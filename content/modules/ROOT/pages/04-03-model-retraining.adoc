= Model Retraining
include::_attributes.adoc[]

To retrain the YOLO model we need a prepared dataset of car images with moderate and severe accident labels.  We have such a dataset (from https://universe.roboflow.com/accident-detection-ffdrf/accident-detection-8dvh5/dataset/1[RoboFlow,window=_blank] ) that has annotated images and has split them into training and validation datasets.  We will use this training set to retrain our currentl YOLO model.

[.bordershadow]
image::04/roboflow-test-images.png[roboflow images]

== Our training data

[%collapsible]
====
1. The encode classes of objects we want to teach our model to detect is 0-'moderate' and 1-'severe'.
2. We have created a folder for the dataset (data) and have have 2 subfolders in it: 'train' and 'valid'.  Within each subfolder we have created 2 subfolders:  'images' and 'labels'.
3. Each image has an annotation text file in the 'labels' subfolder. The annotation text files have the same names as the image files.
====

We have provided the following 2 training data sets, available as 'zip files', and located in an S3 bucket:

1. accident-full.zip - to be used to fully re-train the model.
2. accident-sample.zip - to be used to partially re-train the model when we don't have the time to fully re-train the model.

Your instructor will let you know which data set 'zip file' you will be using in your lab.

Once the images and associated annotations are ready, we create a dataset descriptor YAML file (data.yaml) that points to the created datasets and describes the object classes in them.  This YAML file is passed to the 'train' method of the model to start the training process.

[.bordershadow]
image::04/yaml-file.png[yaml file]

- In your running workbench, navigate to the folder `lab-materials/04`.
- Look for (and open) the notebook called `04-03-model-retraining.ipynb`
- Execute the cells of the notebook. But note that the actual training step would take way too long on CPU, so we will do the training on a sample only. Even with that, you can stop/terminate the kernel if you want if it takes too long to free up resources.


== Interpreting the Model re-Training Results
[%collapsible]
====
Let's start by understanding what an 'epoch' is. Machine learning models are trained with specific datasets passed through the algorithm. Each time a dataset passes through an algorithm, it is said to have completed an epoch. Therefore, epoch, in machine learning, refers to the one entire passing of training data through the algorithm

In the training run below you would see 'n' number of epochs based on the number of epoch training runs you set in the following code snippet:
results = model.train(data='data.yaml', epochs=1, imgsz=640)

In your training run, each epoch will show a summary for both the training and validation phases: lines 1 and 2 show results of the training phase and lines 3 and 4 show the results of the validation phase for each epoch.

image::04/model-retraining-summary.png[retraining summary]

The training phase includes a calculation of the amount of error in a loss function, so the most valuable metrics here are box_loss and cls_loss.

box_loss shows the amount of error in detected bounding boxes.
cls_loss shows the amount of error in detected object classes.

If the model really learns something from the data, then you should see that these values decrease from epoch to epoch.
In a previous screenshot the box_loss decreased: 1.271, 1.113, 0.8679 and the cls_loss decreased too: 1.893, 1.404, 0.9703.

The most valuable quality metric is mAP50-95, which is Mean Average Precision. If the model learns and improves, the precision should grow from epoch to epoch.  In a previous screenshot mAP50-95 increased: 0.314 (epoch1), 0.663 (epoch4), 0.882 (epoch7)

If after the last epoch you did not get acceptable precision, you can increase the number of epochs and run the training again. Also, you can tune other parameters like batch, lr0, lrf or change the optimizer you're using.

During training we export the trained model, after each epoch, to the /runs/detect/train/weights/last.pt file and the model with the highest precision to the /runs/detect/train/weights/best.pt file. So, after training is finished, you can get the best.pt file to use in production.

Note:  In real world problems, you need to run much more epochs (then we have shown here) and be prepared to wait hours or days (like we did!) until training finishes.
====