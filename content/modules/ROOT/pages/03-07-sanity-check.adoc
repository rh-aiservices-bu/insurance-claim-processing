= Sanity-Check Pipeline
:imagesdir: ../assets/images

== What will the pipeline do?
To make sure that everything works as we would expect it, and that the LLM model has not been tampered with, we create a sanity-check pipeline that tests the model through its endpoint. +
We will test the response time, the response quality, and that the model hash has not changed.

== Deploy a pipeline Server in your project

This step was already done as part of the project setup.

// Start by deploying a pipeline server that can we can use to run pipelines with:

// - Go to your Data Science Project
// - Scroll down to Pipelines and press "Create a pipeline server"
// - Select the existing data connection "Pipelines"
// - Press Create

// We need to connect the pipeline server with a data connection as the pipeline server will use the S3 storage to store logs and other artifacts.

== Deploy a sanity-check pipeline

There are two pipeline files, one *sanity_check.pipeline* and one *sanity_check.yaml* file.

The `.pipeline` file can be opened in Elyra to be visually modified and executed, while the `.yaml` file can be imported into the pipeline server through the dashboard. +
Here we will be running the pipeline through Elyra.

== Ad-Hoc execution
Running it through Elyra is the same as doing an ad-hoc execution of the pipeline, as opposed to importing the pipeline which won't automatically execute it.

. Start by going to your running workbench
. Navigate to the folder `insurance-claim-processing/lab-materials/03/07`
. Open up the `sanity_check.pipeline` file
. Here we can see that the pipeline consists of 3 checks:
.. response quality check
.. response time check
.. security check
. Feel free to peek into each of the python files by double clicking on the nodes to see what they do. +
. After the tests have been ran, we have a final function that will summarize the results and log them.
. To run the pipeline, press the Play button in the menu bar.
+
image::03/07-elyra-pipeline.png[elyra sanity pipeline]
. in the popup, leave the name unchanged and click **OK**:
+
image::03/03-07-run-pipeline-ok.png[]

. When you get a popup that says **Job submission to Data Science Pipelines succeeded**, click the link **Run details** to see how the pipeline is progressing.

== Schedule execution

We can also **schedule** an execution so that the sanity check is ran at regular intervals. +
To do that:

. Go back to the OpenShift AI Data Science Project
. Find the pipeline you just ran
. Click the 3 dots at the very end of the line, and click "Create run".
+
image::03/07-create-run.png[create run]

. On the next screen, choose a name, select **Hourly** and click **Create**:

image::03/03-07-hourlyrun.png[]

. We can now leave the sanity-check pipeline alone.
. It will run hourly, and will inform us if anything goes wrong with our LLM model.