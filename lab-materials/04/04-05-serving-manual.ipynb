{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4f4dada-51a8-4f06-9618-0f2deda72bee",
   "metadata": {},
   "source": [
    "# Manually Serve the model \n",
    "\n",
    "In notebook '04-04-accident-recognition' we were able to use the retrained model to predict a 'severe' or 'moderate' car accident within an image.  \n",
    "\n",
    "Next we will determine if we can manually connect with the model from the model server and model pipeline we have created and deployed.  This will be done through an API call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4c9cc-1e3a-43a4-92cf-44af26573030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If you did not use the Workbench image designed for this Lab, you can uncomment and run the following line to install the required packages.\n",
    "#!pip install --no-cache-dir --no-dependencies -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "930247ab-2e10-4db4-888c-517ca3a4cec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in /opt/app-root/lib/python3.9/site-packages (8.0.238)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (1.11.3)\n",
      "Requirement already satisfied: numpy>=1.22.2 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (1.24.4)\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (10.1.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (5.9.6)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (0.13.1)\n",
      "Requirement already satisfied: thop>=0.1.1 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (1.5.3)\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /opt/app-root/lib/python3.9/site-packages (from ultralytics) (3.6.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/app-root/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/app-root/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (4.44.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/app-root/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/app-root/lib/python3.9/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib/python3.9/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (2023.7.22)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib/python3.9/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.4.5.107)\n",
      "Requirement already satisfied: typing-extensions in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (4.8.0)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.3.1)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.18.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (11.0.2.54)\n",
      "Requirement already satisfied: triton==2.1.0 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: sympy in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/app-root/lib/python3.9/site-packages (from torch>=1.8.0->ultralytics) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/app-root/lib/python3.9/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics) (12.3.101)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib/python3.9/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/app-root/lib/python3.9/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ultralytics\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "\n",
    "from remote_infer_rest import ort_v5\n",
    "from remote process_image import perform_inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e84546-979c-4dc2-9fc7-21d997001beb",
   "metadata": {},
   "source": [
    "## Enter the inference URL, the model name, the YAML file with your classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "329ac64a-76a4-4630-8da3-0174fbdf54cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from model internal:  http://modelmesh-serving.user1:8008\n",
    "infer_url = 'https://my-first-model-user1.apps.cluster-r89n6.sandbox766.opentlc.com/v2/models/my-first-model/infer'\n",
    "\n",
    "model_name =  'my-first-model'\n",
    "\n",
    "classes_file = 'datasets/accident-sample/data.yaml'\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74d67e4-1933-4957-80fd-c4b143d14279",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now set the parameters for the inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31725659-710d-4fdc-b195-4d56b299f419",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1. The image you want to analyze\n",
    "image_path ='images/carImage1.jpg' # You can replace this with an image you upload\n",
    "\n",
    "# 2. Confidence threshold, between 0 and 1 (detections with less score won't be retained)\n",
    "conf = 0.2\n",
    "\n",
    "# 3. Intersection over Union Threshold, between 0 and 1 (cleanup overlapping boxes)\n",
    "iou = 0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326d21db-0f7b-4f89-86bd-84f4c04b7c44",
   "metadata": {},
   "source": [
    "## Launch the inference and show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9b8856-b488-4d34-a1d4-6f0ad4295fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#yolo8 model inference from Robert\n",
    "\n",
    "infer = perform_inference(image_path, infer_url)\n",
    "\n",
    "img, out, result = infer()\n",
    "print(f'{result}')\n",
    "print('Predictions:')\n",
    "print(out)\n",
    "print('Format: each detection is a float64 array shaped as [top_left_corner_x, top_left_corner_y, bottom_right_corner_x, bottom_right_corner_y, confidence, class_index]')\n",
    "print('The coordinates are relative to a letterboxed representation of the image of size 640x640')\n",
    "img  = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "fig  = plt.gcf()\n",
    "fig.set_size_inches(24, 12)\n",
    "plt.axis('off')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b126349-9e59-42d4-960d-e1cafba3817d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m infer\u001b[38;5;241m=\u001b[39m\u001b[43mort_v5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfer_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m640\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m img, out, result \u001b[38;5;241m=\u001b[39m infer()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/insurance-claim-processing/lab-materials/04/remote_infer_rest.py:20\u001b[0m, in \u001b[0;36mort_v5.__init__\u001b[0;34m(self, img_path, infer_url, conf_thres, iou_thres, img_size, classes)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size\u001b[38;5;241m=\u001b[39mimg_size\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames\u001b[38;5;241m=\u001b[39m classes\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames_array\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/insurance-claim-processing/lab-materials/04/remote_infer_rest.py:228\u001b[0m, in \u001b[0;36mort_v5.class_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    227\u001b[0m     data \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(f)\n\u001b[0;32m--> 228\u001b[0m classes \u001b[38;5;241m=\u001b[39m [data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m][i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes\n",
      "File \u001b[0;32m~/insurance-claim-processing/lab-materials/04/remote_infer_rest.py:228\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    227\u001b[0m     data \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(f)\n\u001b[0;32m--> 228\u001b[0m classes \u001b[38;5;241m=\u001b[39m [\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnames\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m classes\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "#yolo5 model inference from Guillaume\n",
    "\n",
    "infer=ort_v5(image_path, infer_url, conf, iou, 640, classes_file)\n",
    "img, out, result = infer()\n",
    "print(f'{result}')\n",
    "print('Predictions:')\n",
    "print(out)\n",
    "print('Format: each detection is a float64 array shaped as [top_left_corner_x, top_left_corner_y, bottom_right_corner_x, bottom_right_corner_y, confidence, class_index]')\n",
    "print('The coordinates are relative to a letterboxed representation of the image of size 640x640')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(24, 12)\n",
    "plt.axis('off')\n",
    "plt.imshow(img);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a861f5-4cf3-46ed-9048-57ffa64a295d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8684d170-c1d4-43bf-8a3f-af5da3d31254",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15383c96-08b0-4afb-ba44-88b1f1661e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fba1bf-c79d-439c-9421-d771ba81aba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#define our predict function and pass the path to our model and car image.\n",
    "def predict(best_model_path, car_image_path):\n",
    "    model = YOLO(best_model_path)\n",
    "    results = model.predict(car_image_path)\n",
    "    return results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79374798-8dc6-4235-9d4e-dc1c0e397bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#In the photo draw boxes listing name, probability around each car (object type)\n",
    "def draw_boxes_image(result):\n",
    "    print(\"inside draw boxes image\")\n",
    "    #Image.fromarray(result.plot()[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844cf130-395f-4007-b03c-fb13db838e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#call our predict function\n",
    "prediction_results = predict(\"models/best.pt\", \"images/carImage1.jpg\")\n",
    "Image.fromarray(prediction_results.plot()[:,:,::-1])\n",
    "#draw_boxes_image(prediction_results, image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d08737f-8eb2-44b8-81c7-cd197446ff39",
   "metadata": {},
   "source": [
    "## Extract the Predict function into a Python file\n",
    "Now that we have created a working function, extract the prediction logic into a standalone python file, prediction.py. Also, make sure requirements.txt is updated with any additional packages you have used and need for prediction.\n",
    "\n",
    "## Test the function from your Python file\n",
    "We can make sure the extraction worked properly by loading the function from our prediction.py file and calling it (from our notebook) with the same predict function parameters we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe7cf3-9e59-4070-87b0-9fd1dbf9ebed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#after creating prediction.py, place the predict function inside the file.  Then call the predict method from within our notebook\n",
    "\n",
    "from prediction import predict\n",
    "\n",
    "#image & model file locations.\n",
    "car_image = \"images/carImage1.jpg\"\n",
    "model_path = \"models/best.pt\"\n",
    "\n",
    "#call predict function in prediction.py\n",
    "prediction_results = predict(model_path, car_image)\n",
    "\n",
    "#display image with boxes,class and probability\n",
    "Image.fromarray(prediction_results.plot()[:,:,::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4703d1-89f7-440f-9692-6c647ac0f6f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
